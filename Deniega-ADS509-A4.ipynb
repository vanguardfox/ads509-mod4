{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# John Vincent Deniega\n",
    "# ADS 509 - Fall 2024\n",
    "# 29 September 2024"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes on Political Text\n",
    "\n",
    "In this notebook we use Naive Bayes to explore and classify political data. See the `README.md` for full details."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: This notebook was initiated via a template from the University of San Diego prompt from ADS 509 Module 4 assignment 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "import nltk\n",
    "import random\n",
    "import numpy as np\n",
    "from collections import Counter, defaultdict\n",
    "\n",
    "# Feel free to include your text patterns functions\n",
    "#from text_functions_solutions import clean_tokenize, get_patterns\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from string import punctuation\n",
    "punctuation = set(punctuation)\n",
    "# Stopwords\n",
    "sw = stopwords.words(\"english\")\n",
    "stopwords = set(sw)\n",
    "\n",
    "# Functions from USD's ADS509 Assignment 3's template\n",
    "def remove_punctuation(text, punct_set=punctuation) : \n",
    "    return(\"\".join([ch for ch in text if ch not in punct_set]))\n",
    "def remove_stop(tokens) :\n",
    "    return [word for word in tokens if word not in stopwords]\n",
    "\n",
    "# Automate the cleaning and tokenization process for any text\n",
    "def clean_token(text):\n",
    "    text = ''.join([i for i in text if not i.isdigit()]) # Filter number characters\n",
    "    text = text.lower() # force to lowercase\n",
    "    text = remove_punctuation(text)\n",
    "    tokens = text.split()\n",
    "    tokens = remove_stop(tokens)\n",
    "    return ' '.join(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "convention_db = sqlite3.connect(\"2020_Conventions.db\")\n",
    "convention_cur = convention_db.cursor()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 1: Exploratory Naive Bayes\n",
    "\n",
    "We'll first build a NB model on the convention data itself, as a way to understand what words distinguish between the two parties. This is analogous to what we did in the \"Comparing Groups\" class work. First, pull in the text \n",
    "for each party and prepare it for use in Naive Bayes.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Explore SQL data structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('conventions',)]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set up SQLite connection\n",
    "#conv_db_path = \"Desktop/usd_ADS/github/ads509-mod4/2020_Conventions.db\"\n",
    "conn = convention_db\n",
    "\n",
    "# Get the table names from the database\n",
    "query = \"SELECT name FROM sqlite_master WHERE type='table';\"\n",
    "tables = conn.execute(query).fetchall()\n",
    "tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([(0, 'party', 'TEXT', 0, None, 0),\n",
       "  (1, 'night', 'INTEGER', 0, None, 0),\n",
       "  (2, 'speaker', 'TEXT', 0, None, 0),\n",
       "  (3, 'speaker_count', 'INTEGER', 0, None, 0),\n",
       "  (4, 'time', 'TEXT', 0, None, 0),\n",
       "  (5, 'text', 'TEXT', 0, None, 0),\n",
       "  (6, 'text_len', 'TEXT', 0, None, 0),\n",
       "  (7, 'file', 'TEXT', 0, None, 0)],\n",
       " [('Democratic',\n",
       "   4,\n",
       "   'Unknown',\n",
       "   1,\n",
       "   '00:00',\n",
       "   'Skip to content The Company Careers Press Freelancers Blog Ã— Services Transcription Captions Foreign Subtitles Translation Freelancers About Contact Login Â« Return to Transcript Library home  Transcript Categories  All Transcripts 2020 Election Transcripts Classic Speech Transcripts Congressional Testimony & Hearing Transcripts Debate Transcripts Donald Trump Transcripts Entertainment Transcripts Financial Transcripts Interview Transcripts Political Transcripts Press Conference Transcripts Speech Transcripts Sports Transcripts Technology Transcripts Aug 21, 2020 2020 Democratic National Convention (DNC) Night 4 Transcript Rev  â€º  Blog  â€º  Transcripts  â€º 2020 Election Transcripts  â€º  2020 Democratic National Convention (DNC) Night 4 Transcript Night 4 of the 2020 Democratic National Convention (DNC) on August 20. Read the full transcript of the event here. Transcribe Your Own Content  Try Rev for free  and save time transcribing, captioning, and subtitling.',\n",
       "   '127',\n",
       "   'www_rev_com_blog_transcripts2020-democratic-national-convention-dnc-night-4-transcript.txt'),\n",
       "  ('Democratic',\n",
       "   4,\n",
       "   'Speaker 1',\n",
       "   1,\n",
       "   '00:33',\n",
       "   'Iâ€™m here by calling the full session of the 48th Quadrennial National Convention of the Democratic Party to order. Welcome all to our final session of this historic and memorable convention. Weâ€™ve called the 48th Quadrennial Democratic National Convention to order.',\n",
       "   '41',\n",
       "   'www_rev_com_blog_transcripts2020-democratic-national-convention-dnc-night-4-transcript.txt'),\n",
       "  ('Democratic',\n",
       "   4,\n",
       "   'Speaker 2',\n",
       "   1,\n",
       "   '00:59',\n",
       "   'Every four years, we come together to reaffirm our democracy. This year, weâ€™ve come to save it.',\n",
       "   '17',\n",
       "   'www_rev_com_blog_transcripts2020-democratic-national-convention-dnc-night-4-transcript.txt'),\n",
       "  ('Democratic',\n",
       "   4,\n",
       "   'Kerry Washington',\n",
       "   1,\n",
       "   '01:07',\n",
       "   'We fight for a more perfect union because we are fighting for the soul of this country and for our lives. And right now that fight is real.',\n",
       "   '28',\n",
       "   'www_rev_com_blog_transcripts2020-democratic-national-convention-dnc-night-4-transcript.txt'),\n",
       "  ('Democratic',\n",
       "   4,\n",
       "   'Bernie Sanders',\n",
       "   1,\n",
       "   '01:18',\n",
       "   'We must come together to defeat Donald Trump, and elect Joe Biden and Kamala Harris as our next President and Vice President.',\n",
       "   '22',\n",
       "   'www_rev_com_blog_transcripts2020-democratic-national-convention-dnc-night-4-transcript.txt')])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the column names from the 'conventions' table\n",
    "# Other table structure options can be found in\n",
    "# https://database.guide/4-ways-to-get-information-about-a-tables-structure-in-sqlite/\n",
    "query_columns = \"PRAGMA table_info(conventions);\"\n",
    "columns = conn.execute(query_columns).fetchall()\n",
    "\n",
    "# Show head / top 5 for testing simplicity\n",
    "query_head = \"SELECT * FROM conventions LIMIT 5;\"\n",
    "head = conn.execute(query_head).fetchall()\n",
    "columns,head"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Finding: At this point, we have found that the database has eight columns with counting starting at zero."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "convention_data = []\n",
    "\n",
    "# fill this list up with items that are themselves lists. The \n",
    "# first element in the sublist should be the cleaned and tokenized\n",
    "# text in a single string. The second element should be the party. \n",
    "\n",
    "# Limit to 10 when testing code functionality\n",
    "# Remove when performing full analysis on corpus\n",
    "query_results = convention_cur.execute(\n",
    "                            '''\n",
    "                            SELECT * FROM conventions;\n",
    "                            ''')\n",
    "\n",
    "for row in query_results :\n",
    "    party = row[0] # Extract the first row as the party\n",
    "    text = clean_token(row[5]) # Extract text from \"sixth\" row\n",
    "    convention_data.append([text, party]) # Order as cleaned text then party"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['skip content company careers press freelancers blog Ã— services transcription captions foreign subtitles translation freelancers contact login Â« return transcript library home transcript categories transcripts election transcripts classic speech transcripts congressional testimony hearing transcripts debate transcripts donald trump transcripts entertainment transcripts financial transcripts interview transcripts political transcripts press conference transcripts speech transcripts sports transcripts technology transcripts aug democratic national convention dnc night transcript rev â€º blog â€º transcripts â€º election transcripts â€º democratic national convention dnc night transcript night democratic national convention dnc august read full transcript event transcribe content try rev free save time transcribing captioning subtitling',\n",
       "  'Democratic'],\n",
       " ['iâ€™m calling full session th quadrennial national convention democratic party order welcome final session historic memorable convention weâ€™ve called th quadrennial democratic national convention order',\n",
       "  'Democratic'],\n",
       " ['every four years come together reaffirm democracy year weâ€™ve come save',\n",
       "  'Democratic'],\n",
       " ['fight perfect union fighting soul country lives right fight real',\n",
       "  'Democratic'],\n",
       " ['must come together defeat donald trump elect joe biden kamala harris next president vice president',\n",
       "  'Democratic']]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "convention_data[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at some random entries and see if they look right. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['bully school marched street knocked door dr', 'Democratic'],\n",
       " ['fear live understandably somehow tomorrow said â€œno insurance youâ€™re coveredâ€ devastating hey laura',\n",
       "  'Democratic'],\n",
       " ['', 'Republican'],\n",
       " ['california', 'Democratic'],\n",
       " ['thatâ€™s ran office', 'Democratic'],\n",
       " ['threat nation democracy real itâ€™s clear itâ€™s present weâ€™ve watched president three years look heâ€™s instilling fear mean joking instilling fear showing division stroking racial division undercutting every institution designed check abuse power president anyone else reason order solidify base expand power',\n",
       "  'Democratic'],\n",
       " ['west virginia', 'Republican'],\n",
       " ['also moved joe work going back forth leader wrote violence women act enacted assault weapons ban vice president implemented recovery act brought country back great recessions championed affordable care act protecting millions americans preexisting conditions spent decades promoting american values interests around world',\n",
       "  'Democratic'],\n",
       " ['defenders life individual liberty carry mantle eisenhower reagan force good world one must always reckoned thatâ€™s republican party party lincoln believes america indispensable nation evergreen tree standing tall turbulent world thatâ€™s voting donald trump president thank god bless',\n",
       "  'Republican'],\n",
       " ['president would say â€œletâ€™s take stay home mom run partyâ€ smart guy',\n",
       "  'Republican']]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random.choices(convention_data,k=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If that looks good, we now need to make our function to turn these into features. In my solution, I wanted to keep the number of features reasonable, so I only used words that occur at least `word_cutoff` times. Here's the code to test that if you want it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With a word cutoff of 5, we have 2341 as features in the model.\n"
     ]
    }
   ],
   "source": [
    "word_cutoff = 5\n",
    "\n",
    "tokens = [w for t, p in convention_data for w in t.split()]\n",
    "\n",
    "word_dist = nltk.FreqDist(tokens)\n",
    "\n",
    "feature_words = set()\n",
    "\n",
    "for word, count in word_dist.items() :\n",
    "    if count > word_cutoff :\n",
    "        feature_words.add(word)\n",
    "        \n",
    "print(f\"With a word cutoff of {word_cutoff}, we have {len(feature_words)} as features in the model.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_features(text,fw) :\n",
    "    \"\"\"Given some text, this returns a dictionary holding the\n",
    "       feature words.\n",
    "       \n",
    "       Args: \n",
    "            * text: a piece of text in a continuous string. Assumes\n",
    "            text has been cleaned and case folded.\n",
    "            * fw: the *feature words* that we're considering. A word \n",
    "            in `text` must be in fw in order to be returned. This \n",
    "            prevents us from considering very rarely occurring words.\n",
    "        \n",
    "       Returns: \n",
    "            A dictionary with the words in `text` that appear in `fw`. \n",
    "            Words are only counted once. \n",
    "            If `text` were \"quick quick brown fox\" and `fw` = {'quick','fox','jumps'},\n",
    "            then this would return a dictionary of \n",
    "            {'quick' : True,\n",
    "             'fox' :    True}\n",
    "        \n",
    "    \"\"\"\n",
    "    \n",
    "    words = text.split() # Split on whitespace by default\n",
    "    ret_dict = dict() # Initialize dictionary\n",
    "    for word in words: # Iterate through all tokens (on whitespace) from the given \"text\"\n",
    "        if word in fw and word not in ret_dict: # Ensure token is only set True on first read\n",
    "            ret_dict[word] = True\n",
    "    \n",
    "    return(ret_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Testing with assert statement on conv_features function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert(len(feature_words)>0)\n",
    "assert(conv_features(\"donald is the president\",feature_words)==\n",
    "       {'donald':True,'president':True})\n",
    "assert(conv_features(\"people are american in america\",feature_words)==\n",
    "                     {'america':True,'american':True,\"people\":True})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we'll build our feature set. Out of curiosity I did a train/test split to see how accurate the classifier was, but we don't strictly need to since this analysis is exploratory. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "featuresets = [(conv_features(text,feature_words), party) for (text, party) in convention_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(20220507)\n",
    "random.shuffle(featuresets)\n",
    "\n",
    "test_size = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.496\n"
     ]
    }
   ],
   "source": [
    "test_set, train_set = featuresets[:test_size], featuresets[test_size:]\n",
    "classifier = nltk.NaiveBayesClassifier.train(train_set)\n",
    "print(nltk.classify.accuracy(classifier, test_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most Informative Features\n",
      "                   china = True           Republ : Democr =     25.8 : 1.0\n",
      "                   votes = True           Democr : Republ =     23.8 : 1.0\n",
      "             enforcement = True           Republ : Democr =     21.5 : 1.0\n",
      "                 destroy = True           Republ : Democr =     19.2 : 1.0\n",
      "                freedoms = True           Republ : Democr =     18.2 : 1.0\n",
      "                 climate = True           Democr : Republ =     17.8 : 1.0\n",
      "                supports = True           Republ : Democr =     17.1 : 1.0\n",
      "                   crime = True           Republ : Democr =     16.1 : 1.0\n",
      "                   media = True           Republ : Democr =     14.9 : 1.0\n",
      "                 beliefs = True           Republ : Democr =     13.0 : 1.0\n",
      "               countries = True           Republ : Democr =     13.0 : 1.0\n",
      "                 defense = True           Republ : Democr =     13.0 : 1.0\n",
      "                    isis = True           Republ : Democr =     13.0 : 1.0\n",
      "                 liberal = True           Republ : Democr =     13.0 : 1.0\n",
      "                religion = True           Republ : Democr =     13.0 : 1.0\n",
      "                   trade = True           Republ : Democr =     12.7 : 1.0\n",
      "                    flag = True           Republ : Democr =     12.1 : 1.0\n",
      "               greatness = True           Republ : Democr =     12.1 : 1.0\n",
      "                 abraham = True           Republ : Democr =     11.9 : 1.0\n",
      "                  defund = True           Republ : Democr =     11.9 : 1.0\n",
      "                    drug = True           Republ : Democr =     10.9 : 1.0\n",
      "              department = True           Republ : Democr =     10.9 : 1.0\n",
      "               destroyed = True           Republ : Democr =     10.9 : 1.0\n",
      "                   enemy = True           Republ : Democr =     10.9 : 1.0\n",
      "               amendment = True           Republ : Democr =     10.3 : 1.0\n"
     ]
    }
   ],
   "source": [
    "classifier.show_most_informative_features(25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write a little prose here about what you see in the classifier. Anything odd or interesting? It appears that the classifier on its own using the training and test set on a single word or single n-gram still only provides a roughly 50/50 accuracy on two labels. This suggests that this method may be no better than a random guesser.\n",
    "\n",
    "### My Observations\n",
    "\n",
    "In addition to the above observation, it is notable that 23 of the top 25 most informative features are Republican words ranging from 25.8 to 1 to 10.3 to 1. This is suggests that Republican text key words are far more emphasized relative to the corpus than that of the top words in the Democratic text. This also suggests that the inverse is true in that these words are negative indicators of the opposite party. For example, if the word \"china\" appears in a text, then is both an indicator that it is strongly Republican, but also an indicator that the text is very unlikely Democratic. The key word, \"votes\" would apply in the opposite manner.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Classifying Congressional Tweets\n",
    "\n",
    "In this part we apply the classifer we just built to a set of tweets by people running for congress\n",
    "in 2018. These tweets are stored in the database `congressional_data.db`. That DB is funky, so I'll\n",
    "give you the query I used to pull out the tweets. Note that this DB has some big tables and \n",
    "is unindexed, so the query takes a minute or two to run on my machine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "cong_db = sqlite3.connect(\"congressional_data.db\")\n",
    "cong_cur = cong_db.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = cong_cur.execute(\n",
    "        '''\n",
    "           SELECT DISTINCT \n",
    "                  cd.candidate, \n",
    "                  cd.party,\n",
    "                  tw.tweet_text\n",
    "           FROM candidate_data cd \n",
    "           INNER JOIN tweets tw ON cd.twitter_handle = tw.handle \n",
    "               AND cd.candidate == tw.candidate \n",
    "               AND cd.district == tw.district\n",
    "           WHERE cd.party in ('Republican','Democratic') \n",
    "               AND tw.tweet_text NOT LIKE '%RT%'\n",
    "        ''')\n",
    "\n",
    "results = list(results) # Just to store it, since the query is time consuming"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Verify results are listed as expected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Mo Brooks',\n",
       "  'Republican',\n",
       "  b'\"Brooks Joins Alabama Delegation in Voting Against Flawed Funding Bill\" http://t.co/3CwjIWYsNq'),\n",
       " ('Mo Brooks',\n",
       "  'Republican',\n",
       "  b'\"Brooks: Senate Democrats Allowing President to Give Americans\\xe2\\x80\\x99 Jobs to Illegals\" #securetheborder https://t.co/mZtEaX8xS6'),\n",
       " ('Mo Brooks',\n",
       "  'Republican',\n",
       "  b'\"NASA on the Square\" event this Sat. 11AM \\xe2\\x80\\x93 4PM. Stop by &amp; hear about the incredible work done in #AL05! @DowntownHSV http://t.co/R9zY8WMEpA'),\n",
       " ('Mo Brooks',\n",
       "  'Republican',\n",
       "  b'\"The trouble with Socialism is that eventually you run out of other people\\'s money.\" - Margaret Thatcher https://t.co/X97g7wzQwJ'),\n",
       " ('Mo Brooks',\n",
       "  'Republican',\n",
       "  b'\"The trouble with socialism is eventually you run out of other people\\'s money\" \\xe2\\x80\\x93 Thatcher. She\\'ll be sorely missed. http://t.co/Z8gBnDQUh8')]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_data = []\n",
    "\n",
    "# Now fill up tweet_data with sublists like we did on the convention speeches.\n",
    "# Note that this may take a bit of time, since we have a lot of tweets.\n",
    "\n",
    "for row in results:\n",
    "    party = row[1] # Parse that row's party\n",
    "    tweet = row[2].decode('utf-8') # Parse the tweet from the \"third\" row\n",
    "    tweet_data.append([tweet, party]) # Add this row's entry tuple as a list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['\"Brooks Joins Alabama Delegation in Voting Against Flawed Funding Bill\" http://t.co/3CwjIWYsNq',\n",
       "  'Republican'],\n",
       " ['\"Brooks: Senate Democrats Allowing President to Give Americansâ€™ Jobs to Illegals\" #securetheborder https://t.co/mZtEaX8xS6',\n",
       "  'Republican'],\n",
       " ['\"NASA on the Square\" event this Sat. 11AM â€“ 4PM. Stop by &amp; hear about the incredible work done in #AL05! @DowntownHSV http://t.co/R9zY8WMEpA',\n",
       "  'Republican'],\n",
       " ['\"The trouble with Socialism is that eventually you run out of other people\\'s money.\" - Margaret Thatcher https://t.co/X97g7wzQwJ',\n",
       "  'Republican'],\n",
       " ['\"The trouble with socialism is eventually you run out of other people\\'s money\" â€“ Thatcher. She\\'ll be sorely missed. http://t.co/Z8gBnDQUh8',\n",
       "  'Republican']]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweet_data[:5] # Check the first five like a head(5) function call"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are a lot of tweets here. Let's take a random sample and see how our classifer does. I'm guessing it won't be too great given the performance on the convention speeches..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(20201014)\n",
    "\n",
    "tweet_data_sample = random.choices(tweet_data,k=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Repeat the word cutoff step from conventions for tweet data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With a word cutoff of 5, we have 80481 as features in the model.\n"
     ]
    }
   ],
   "source": [
    "word_cutoff = 5\n",
    "\n",
    "tokens = [w for t, p in tweet_data for w in t.split()]\n",
    "\n",
    "word_dist = nltk.FreqDist(tokens)\n",
    "\n",
    "feature_words = set()\n",
    "\n",
    "for word, count in word_dist.items() :\n",
    "    if count > word_cutoff :\n",
    "        feature_words.add(word)\n",
    "        \n",
    "print(f\"With a word cutoff of {word_cutoff}, we have {len(feature_words)} as features in the model.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Repeat the train, test split from conventions for tweet data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.656\n"
     ]
    }
   ],
   "source": [
    "featuresets = [(conv_features(text,feature_words), party) for (text, party) in tweet_data]\n",
    "test_set, train_set = featuresets[:test_size], featuresets[test_size:]\n",
    "classifier = nltk.NaiveBayesClassifier.train(train_set)\n",
    "print(nltk.classify.accuracy(classifier, test_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here's our (cleaned) tweet: Earlier today, I spoke on the House Floor abt protecting health care for women and praised @PPmarmonte for their work on the Central Coast. https://t.co/WqgTRzT7VV\n",
      "Actual party is Democratic and our classifer says Democratic.\n",
      "\n",
      "Here's our (cleaned) tweet: Go Tribe! #RallyTogether https://t.co/0NXutFL9L5\n",
      "Actual party is Democratic and our classifer says Republican.\n",
      "\n",
      "Here's our (cleaned) tweet: Apparently, Trump thinks it's just too easy for students overwhelmed by the crushing burden of debt to pay off student loans #TrumpBudget https://t.co/ckYQO5T0Qh\n",
      "Actual party is Democratic and our classifer says Democratic.\n",
      "\n",
      "Here's our (cleaned) tweet: Weâ€™re grateful for our first responders, our rescue personnel, our firefighters, our police, and volunteers who have been working tirelessly to keep people safe, provide much-needed help, while putting their own lives on the line.\n",
      "\n",
      "https://t.co/eZPv0vMIz3\n",
      "Actual party is Republican and our classifer says Democratic.\n",
      "\n",
      "Here's our (cleaned) tweet: Letâ€™s make it even Greater !! #KAG ðŸ‡ºðŸ‡¸ https://t.co/y9qoZD5L2z\n",
      "Actual party is Republican and our classifer says Republican.\n",
      "\n",
      "Here's our (cleaned) tweet: We have about 1hr until the @cavs tie up the series 2-2. I'm #ALLin216 @RepBarbaraLee you scared? #roadtovictory\n",
      "Actual party is Democratic and our classifer says Democratic.\n",
      "\n",
      "Here's our (cleaned) tweet: Congrats to @belliottsd on his new gig at SD City Hall. We are glad you will continue to serveâ€¦ https://t.co/fkvMw3cqdI\n",
      "Actual party is Democratic and our classifer says Democratic.\n",
      "\n",
      "Here's our (cleaned) tweet: We are really close, we have over $3500 raised toward the match right now. Whoot!! (Thatâ€™s $7000 for the non-math majors in the room ðŸ˜‚). Help us get there https://t.co/Tu34C472sD https://t.co/QsdQkYpsmC\n",
      "Actual party is Democratic and our classifer says Democratic.\n",
      "\n",
      "Here's our (cleaned) tweet: Today, the comment period for @POTUSâ€™s plan to expand offshore drilling opened to the public. You have 60 days (until March 9) to share why you oppose the proposed program directly with the Trump Administration. Comments can be made by email or mail. https://t.co/BaaYMeJxQn\n",
      "Actual party is Democratic and our classifer says Democratic.\n",
      "\n",
      "Here's our (cleaned) tweet: Celebrated @ICSEastLAâ€™s 22 years of Eastside commitment &amp; saluted community leaders at last nightâ€™s awards dinner! https://t.co/7V7gH8giVB\n",
      "Actual party is Democratic and our classifer says Democratic.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for tweet, party in tweet_data_sample :\n",
    "    # Get the estimated party using the classifier\n",
    "    # Reference\n",
    "    # https://www.nltk.org/api/nltk.classify.naivebayes.html\n",
    "    estimated_party = classifier.classify(conv_features(tweet, feature_words))\n",
    "    # Fill in the right-hand side above with code that estimates the actual party\n",
    "    \n",
    "    print(f\"Here's our (cleaned) tweet: {tweet}\")\n",
    "    print(f\"Actual party is {party} and our classifer says {estimated_party}.\")\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we've looked at it some, let's score a bunch and see how we're doing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dictionary of counts by actual party and estimated party. \n",
    "# first key is actual, second is estimated\n",
    "parties = ['Republican','Democratic']\n",
    "results = defaultdict(lambda: defaultdict(int))\n",
    "\n",
    "for p in parties :\n",
    "    for p1 in parties :\n",
    "        results[p][p1] = 0\n",
    "\n",
    "\n",
    "num_to_score = 10000\n",
    "random.shuffle(tweet_data)\n",
    "\n",
    "for idx, tp in enumerate(tweet_data) :\n",
    "    tweet, party = tp    \n",
    "    # Now do the same thing as above, but we store the results rather\n",
    "    # than printing them. \n",
    "   \n",
    "    # get the estimated party (Note, copy-pasted right side like above)\n",
    "    estimated_party = classifier.classify(conv_features(tweet, feature_words))\n",
    "    \n",
    "    results[party][estimated_party] += 1\n",
    "    \n",
    "    if idx > num_to_score : \n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(<function __main__.<lambda>()>,\n",
       "            {'Republican': defaultdict(int,\n",
       "                         {'Republican': 2393, 'Democratic': 1885}),\n",
       "             'Democratic': defaultdict(int,\n",
       "                         {'Republican': 329, 'Democratic': 5395})})"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reflections\n",
    "\n",
    "Based on the results, given Republican tweets, the classifier was 55.94 percent accurate. This is in stark contrast given Democratic tweets where the classifer was 94.25 percent accurate. Further exploration into the data is needed to identify why there's such a disparity in performance by party affiliation. Initial impressions suggest that Republican tweets may be more politically ambiguous relative to those of their Democratic collegues, which may be a result of party tendencies to use the given medium, Twitter. Further, given the accuracy of Democratic tweets by the Naive Bayes classifier, it may suggest that there's a strong set of feature words that are largely indicative of Democratic party affiliation. Finally, there may be an opportunity to use the key words from the convention data based on most important features to further refine this model."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
